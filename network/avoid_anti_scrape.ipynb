{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何绕过反扒机制\n",
    "\n",
    "为了避开常见的反爬机制，需要3个措施：\n",
    "\n",
    "1. 使用代理IP，在请求时进行轮换\n",
    "2. 使用不同的User-Agent\n",
    "3. 降低请求频率，随机化前后两次的请求时间\n",
    "\n",
    "教程：\n",
    "\n",
    "* https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/\n",
    "* https://www.scrapehero.com/how-to-rotate-proxies-and-ip-addresses-using-python-3/\n",
    "* https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 使用代理IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们需要一个函数检测代理IP的有效性。\n",
    "\n",
    "通过访问[httpbin.org](https://httpbin.org/ip)，可以返回发送请求的真实IP，如果该IP与代理相同，证明代理是有效的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_proxy(proxy: str) -> bool:\n",
    "    \"\"\"测试代理IP是否有效\n",
    "\n",
    "    Args:\n",
    "        proxy(str): 代理IP\n",
    "            基础格式：'http://ip:port'\n",
    "            需要认证：'http://user:pass@ip:port/'\n",
    "\n",
    "    Returns:\n",
    "        代理有效返回True, 无效返回False\n",
    "    \"\"\"\n",
    "    proxies = {\"http\": proxy, \"https\": proxy}\n",
    "    try:\n",
    "        resp = requests.get(\n",
    "            \"https://httpbin.org/ip\", proxies=proxies, timeout=3)\n",
    "        resp.raise_for_status()\n",
    "    except Exception:\n",
    "        return False\n",
    "    else:\n",
    "        origin = resp.json()[\"origin\"]\n",
    "        proxy_ip = re.search(\n",
    "            r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", proxy).group()\n",
    "        return proxy_ip == origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 免费代理\n",
    "\n",
    "从[free-proxy-list.net](https://free-proxy-list.net/)获取免费的代理IP。\n",
    "\n",
    "网上虽然有大量的免费代理可以使用，但效果很糟糕，因为使用的人太多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freeproxy_proxies() -> List[str]:\n",
    "    resp = requests.get(\"https://free-proxy-list.net/\")\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    proxies = []\n",
    "    for row in soup.find(\"table\", {\"id\": \"proxylisttable\"}).tbody.children:\n",
    "        proxy = \":\".join([col.get_text() for col in row.find_all(\"td\")[:2]])\n",
    "        proxies.append(proxy)\n",
    "\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['119.28.65.21:80',\n",
       " '192.41.19.53:3128',\n",
       " '64.137.175.85:3128',\n",
       " '208.80.28.208:8080',\n",
       " '216.250.236.11:3128']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies = get_freeproxy_proxies()\n",
    "proxies[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.28.65.21:80: False\n",
      "192.41.19.53:3128: True\n",
      "64.137.175.85:3128: False\n",
      "208.80.28.208:8080: False\n",
      "216.250.236.11:3128: True\n"
     ]
    }
   ],
   "source": [
    "for proxy in proxies[:5]:\n",
    "    res = test_proxy(proxy)\n",
    "    print(f\"{proxy}: {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 付费代理\n",
    "\n",
    "WeShare: 免费用户可获得10个私有代理IP，每月1G流量。\n",
    "\n",
    "为什么使用WeShare:\n",
    "\n",
    "* 免费体验计划\n",
    "* 付费成本较低\n",
    "* 代理质量比较高\n",
    "* 提供REST API查询代理IP和使用情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weshare_proxies() -> List[str]:\n",
    "    url = os.getenv(\"WESHARE_URL\")\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['209.127.191.180:80',\n",
       " '45.130.255.243:80',\n",
       " '185.164.56.20:80',\n",
       " '45.130.255.198:80',\n",
       " '185.30.232.123:80',\n",
       " '45.95.96.132:80',\n",
       " '45.95.96.237:80',\n",
       " '45.95.96.187:80',\n",
       " '45.94.47.66:80',\n",
       " '193.8.56.119:80']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies = get_weshare_proxies()\n",
    "proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.127.191.180:80: True\n",
      "45.130.255.243:80: True\n",
      "185.164.56.20:80: True\n",
      "45.130.255.198:80: False\n",
      "185.30.232.123:80: True\n",
      "45.95.96.132:80: False\n",
      "45.95.96.237:80: False\n",
      "45.95.96.187:80: False\n",
      "45.94.47.66:80: True\n",
      "193.8.56.119:80: True\n"
     ]
    }
   ],
   "source": [
    "username = os.getenv(\"WESHARE_USERNAME\")\n",
    "password = os.getenv(\"WESHARE_PASSWORD\")\n",
    "for proxy in proxies:\n",
    "    res = test_proxy(f\"http://{username}:{password}@{proxy}/\")\n",
    "    print(f\"{proxy}: {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 轮换User-Agent\n",
    "\n",
    "#### 什么是User-Agent?\n",
    "\n",
    "User-Agent即用户代理，这是浏览器/爬虫发送给服务器的一个字符串，描述一些重要信息，例如浏览器版本，操作系统等，服务器可以利用这些信息做优化，例如优化网页加载速度。User-Agent通常作为请求头(request header)的一部分发送给服务器。\n",
    "\n",
    "#### 为什么要使用User-Agent?\n",
    "\n",
    "反扒机制一般会对User-Agent进行检查，如果发现不是浏览器发出的请求，很可能会拒绝请求。\n",
    "\n",
    "以Python requests为例，默认User-Agent包含'python'字样，很容易就被识别为程序发送的请求。\n",
    "\n",
    "#### 为什么要轮换User-Agent?\n",
    "\n",
    "如果要对一个网站进行数千次爬取，最好的办法是每次请求都使用不同的IP和headers，伪装成是不同地区不同的浏览器在对网站发出请求，这样反扒机制就很难识别你的爬虫。\n",
    "\n",
    "#### 如何实现轮换？\n",
    "\n",
    "1. 半自动轮换。\n",
    "\n",
    "从网上收集User-Agent，构建一个列表，每次请求时随机抽取，更新headers，然后发送请求。\n",
    "\n",
    "* https://deviceatlas.com/blog/list-of-user-agent-strings\n",
    "* https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent\n",
    "* https://www.whoishostingthis.com/tools/user-agent/\n",
    "\n",
    "2. 自动轮换。使用三方库'fake-headers'自动生成用户代理。\n",
    "\n",
    "有时候仅仅提供User-Agent是不够的，有的网站会要求提供特定的请求头字段，在爬取之前先用浏览器开发工具检查请求头，复制下来，然后在请求时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headers': {'Accept': '*/*',\n",
       "  'Accept-Encoding': 'gzip, deflate',\n",
       "  'Host': 'httpbin.org',\n",
       "  'User-Agent': 'python-requests/2.24.0',\n",
       "  'X-Amzn-Trace-Id': 'Root=1-5f9ebb9e-24c315134621879c26a93b7c'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = requests.get(\"http://httpbin.org/headers\")\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from fake_headers import Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accept': '*/*',\n",
      " 'Connection': 'keep-alive',\n",
      " 'User-Agent': 'Mozilla/5.0 (X11; Linux i686 on x86_64; rv:58.0.2) '\n",
      "               'Gecko/20100101 Firefox/58.0.2'}\n",
      "{'Accept': '*/*',\n",
      " 'Connection': 'keep-alive',\n",
      " 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) '\n",
      "               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 '\n",
      "               'Safari/537.36 OPR/55.0.2994.37'}\n",
      "{'Accept': '*/*',\n",
      " 'Connection': 'keep-alive',\n",
      " 'User-Agent': 'Mozilla/5.0 (Windows NT 6.0; Win64; x64; rv:62.0.2) '\n",
      "               'Gecko/20100101 Firefox/62.0.2'}\n"
     ]
    }
   ],
   "source": [
    "header = Headers(headers=False)  # 生成最简headers,随机用户代理\n",
    "\n",
    "for _ in range(3):\n",
    "    pprint(header.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accept': '*/*',\n",
      " 'Accept-Encoding': 'gzip, deflate, br',\n",
      " 'Accept-Language': 'en-US;q=0.5,en;q=0.3',\n",
      " 'Cache-Control': 'max-age=0',\n",
      " 'Connection': 'keep-alive',\n",
      " 'DNT': '1',\n",
      " 'Referer': 'https://google.com',\n",
      " 'Upgrade-Insecure-Requests': '1',\n",
      " 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_6) '\n",
      "               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.62 '\n",
      "               'Safari/537.36'}\n",
      "{'Accept': '*/*',\n",
      " 'Accept-Language': 'en-US;q=0.5,en;q=0.3',\n",
      " 'Cache-Control': 'max-age=0',\n",
      " 'Connection': 'keep-alive',\n",
      " 'Pragma': 'no-cache',\n",
      " 'Upgrade-Insecure-Requests': '1',\n",
      " 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like '\n",
      "               'Gecko) Chrome/70.0.3538.80 Safari/537.36 OPR/56.0.3051.116'}\n",
      "{'Accept': '*/*',\n",
      " 'Accept-Encoding': 'gzip, deflate, br',\n",
      " 'Connection': 'keep-alive',\n",
      " 'Pragma': 'no-cache',\n",
      " 'Upgrade-Insecure-Requests': '1',\n",
      " 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) '\n",
      "               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 '\n",
      "               'Safari/537.36 OPR/55.0.2994.61'}\n"
     ]
    }
   ],
   "source": [
    "header = Headers(headers=True)  # 生成包含大量信息的请求头\n",
    "\n",
    "for _ in range(3):\n",
    "    pprint(header.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m58"
  },
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "quant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
